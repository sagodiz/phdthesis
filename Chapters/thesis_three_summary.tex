We took an alternative form of source code generation and used to generate fixed source code to perform so called automatic program repair.
We used GPT-4 to generate the source code in a way that maintains the original functionality without the hidden vulnerability inside.

This task is evaluated on a real-life vulnerability benchmark, Vul4J.
This benchmarks contains tests that validate whether the plausible fix correctly removes the vulnerability or not.
To prevent our results to be influenced by GPT-4 being familiar with the vulnerabilities collected in the benchmark, We also used a benchmark, which had no validation tests, thus We could check correctness only by hand, that has vulnerabilities only after the training period of that particular GPT-4 version.

We created our prompt by considering multiple prompting strategies and we selected the best performing on a sub-set of Vul4J.
With our prompt, we prompted GPT-4 to fix the source code and also provide a textual answer.
This two sided request allowed us to discover if GPT can be a useful guide even if it cannot provide a valid vulnerability fix.
Our findings show that in real-world scenario the GPT-4 model can fix 33.33\% of the vulnerabilities  and can provide useful answers in around 50\% of the cases.
